<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN" "http://www.w3.org/TR/html4/strict.dtd">
<html>
<head>
<title>Title</title>
<link href="style.css" rel="stylesheet" type="text/css">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
</head>
<body>












<p style='text-align: center'><img src="http://www.uia.no/no/content/download/79969/1326369/file/UiA+logo+engelsk.jpg" width="50%" height="50%" alt="UiA Logo"></p>
<p><br></p>
<p><br></p>

<div style="font-size: 16pt; text-align: center"><b>Adaptive Game Difficulty</b></div>

<p><br></p>
<p style="text-align: center">By<br>
<br>Jon Vegard Jansen, Robin Tollisen
</p>
<p style='text-align: center'>Supervisor: Sondre Glimsdal<br><br></p>
<p style='text-align: center'><b>Project report for IKT411 in Spring 2013</b><br><br></p>
<p style="text-align: center">Faculty of Engineering and Science
<br>University of Agder
<br>Grimstad, 7th of June
</p>

<p style='text-align: center'>Status: Final</p>
<p><b>Keywords:</b> E-learning, gamification, unsupervised online learning, stochastic hill climbing, maximize fun<br></p>

<p><b>Abstract:</b><br>Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.</p>


<h1 id='toc' class='notoc'>Table of contents</h1>
<p>
"Husk class='notoc'"
</p>

<div>
<a href='#intro' class='toc_1'>Introduction</a><br>
<a href='#background' class='toc_2'>Background</a><br>
<a href='#introduction_-_problem_statement' class='toc_2'>Problem Statement</a><br>
<a href='#introduction_-_problem_solution' class='toc_2'>Problem Solution</a><br>
<a href='#shc' class='toc_1'>Stochastic hill climbing</a><br>
<a href='#stochastic_hill_climbing_-_stochastic_hill_climbing_example' class='toc_2'>Stochastic hill climbing example</a><br>
<a href='#solution' class='toc_1'>Solution</a><br>
<a href='#solution_-_algorithm' class='toc_2'>Algorithm</a><br>
<a href='#solution_-_litt_lang_setning__som_er_en_hel_paragraf_' class='toc_2'>Litt lang setning, som er en hel paragraf?</a><br>
<a href='#game_description' class='toc_1'>Game Description</a><br>
<a href='#game_description_-_genre' class='toc_2'>Genre</a><br>
<a href='#game_description_-_our_game' class='toc_2'>Our game</a><br>
<a href='#testing' class='toc_1'>Testing</a><br>
<a href='#testing_-_difficulty_testing' class='toc_2'>Difficulty testing</a><br>
<a href='#fun_testing' class='toc_2'>Fun testing</a><br>
<a href='#discussion' class='toc_1'>Discussion</a><br>
<a href='#discfun' class='toc_2'>Discussing the fun testing</a><br>
<a href='#discussion_-_discussing_the_difficulty_testing' class='toc_2'>Discussing the difficulty testing</a><br>
<a href='#observations' class='toc_2'>Other observations</a><br>
<a href='#conclusion' class='toc_1'>Conclusion</a><br>
<a href='#future_work' class='toc_1'>Future Work</a><br>
<a href='#references' class='toc_1'>References</a><br>
</div>


<h1 id='table_of_figures' class='notoc'>Table of figures</h1>
<p>
"Husk class='notoc'"
</p>

<div>
<a href='#hclocalmaximum' class='figtoc'>A function that has a local maximum</a><br>
<a href='#hcflat' class='figtoc'>A function that is too flat to search on</a><br>
<a href='#hcsteep' class='figtoc'>A function that is very steep</a><br>
<a href='#hcex1' class='figtoc'>The startpoint for the search</a><br>
<a href='#hcex2' class='figtoc'>The first jump</a><br>
<a href='#hcex3' class='figtoc'>An attempted jump</a><br>
<a href='#hcex4' class='figtoc'>Achieving global maximum</a><br>
<a href='#hcex5' class='figtoc'>Further jumps are discarded</a><br>
<a href='#pseudoalgorithm' class='figtoc'>Pseudo-code for the algorithm.</a><br>
<a href='#algorithmexample' class='figtoc'>The flow of our algorithm.</a><br>
<a href='#pseudorelations' class='figtoc'>Pseudo-code for jumping of relations</a><br>
<a href='#relationsexample' class='figtoc'>Basic relations example.</a><br>
<a href='#difficultyexample' class='figtoc'>Difficulty does not change in relations.</a><br>
</div>


<h1 id='table_of_tables' class='notoc'>Table of tables</h1>
<p>
"Husk class='notoc'"
</p>

<div>
<a href='#testing' class='tabletoc'>Test results for fun testing</a><br>
<a href='#testing2' class='tabletoc'>Before-and-after test results</a><br>
</div>


<h1 id='intro'>Introduction</h1>
<p>
Today, there exists more commercial video and computer games (henceforth: games) than ever before, and the number of persons owning a smart-phone or personal computer is increasing. Many students and pupils neglect their studies in favor of watching television or playing games, maybe because they consider it more fun. We believe that through the use of E-learning and gamification, which enhances traditional learning methods with elements from games, it is possible to make any learning process more fun, resulting in more interested students and better grades.
</p>

<p>
As each student is unique, we believe that they also have different learning methods that work best for them, which is why we have chosen to look into adaptive games. In this project we research whether a game can be made, such that it adapts to each player on the fly.
</p>

<h2 id='background'>Background</h2>
<p>
A lot of research has already been done on the area of E-learning, and there exists multiple definitions. We have chosen to use the following one, because it emphasizes the individual student, which goes hand in hand with individual adaption of application.
</p>

<i>"We will call e-Learning all forms of electronic supported learning and teaching, which ... aim to effect the construction of knowledge with reference to individual experience, practive and knowledge of the learner..."</i> <a href='#reference_1' title='Tavangarian, D., Leypold, M. E., Nölting, K., Röser, M., & Voigt, D. (2004). Is e-learning the Solution for Individual Learning. <i>Electronic Journal of E-learning</i>, 2(2), 273-280.'>[1]</a>.

<p>
Gamification is a concept that has been around for a long time, and has increased with popularity since 2010. <a href='#reference_2' title='Marczewski, A. (2012). <i>Gamification: A Simple Introduction.</i> Andrzej Marczewski.'>[2]</a> <a href='#reference_3' title='Zichermann, G., & Cunningham, C. (2011). <i>Gamification by design: Implementing game mechanics in web and mobile apps.</i> O'Reilly Media.'>[3]</a>. We present the two following definitions, as we think both of them show that gamification can be used well in conjunction with E-learning.
</p>
 
<i>"The process of game-thinking and game mechanics to engage users and solve problems."</i> <a href='#reference_3' title='Zichermann, G., & Cunningham, C. (2011). <i>Gamification by design: Implementing game mechanics in web and mobile apps.</i> O'Reilly Media.'>[3]</a>.<br/>
<br/>
<i>"A process of enhancing a service with affordances for gameful experiences in order to support user's overall value creation."</i> <a href='#reference_4' title='Huotari, K., & Hamari, J. (2012, October). Defining gamification: a service marketing perspective. In <i>Proceeding of the 16th International Academic MindTrek Conference</i> (pp. 17-22). ACM.'>[4]</a>.

<p>
The latter definition is directed towards service marketing, but if one reads 'service' as 'learning process' and 'user's overall value creation' as 'learning outcomes', we believe that gamification is something that could be used together with both tradition learning methods and E-learning.
</p>

<p>
While we believe in the concept of gamification, for this project we will create our own game to test an algorithm for adaptive games.
</p>

<p>
If one is to create a game that is meant for learning purposes, it is important to note that the game needs to be fun. <a href='#reference_3' title='Zichermann, G., & Cunningham, C. (2011). <i>Gamification by design: Implementing game mechanics in web and mobile apps.</i> O'Reilly Media.'>[3]</a>. If a game is not fun, it will not be able to educate either, because players lose interest in games the same way as students lose interest lectures, should they be boring. This is why it is important to figure out how it is possible to maximize the fun in any kind of game, thus keeping the interest of players. Since games appeal to a wide variety of players, the perceived level of fun may often vary among its players, due to personal preferences. In order to accomodote for such varying preferences, traditional games have often implemented several levels of difficulty the player may choose from, as well as providing the player with several settings or options for how they want the game to behave. When it comes to difficulty, other work has already been done on how to scale and adapt this to the level of player, in order to make even games, but in order to make a game fun, we believe that more than difficulty needs to adapt to individual preferences, thus more aspects of a game should be able to change on the fly. <a href='#reference_5' title='Spronck, P., Sprinkhuizen-Kuyper, I., & Postma, E. (2004). Difficulty scaling of game AI. In <i>Proceedings of the 5th International Conference on Intelligent Games and Simulation (GAME-ON 2004)</i> (pp. 33-37).'>[5]</a>.
</p>

<h2 id='introduction_-_problem_statement'>Problem Statement</h2>
<p>
Our project is to research whether it is possible to create a game, that uses an unsupervised online learning algorithm, which will adapt the game to the user's preferences based on limited user feedback.
</p>

<h2 id='introduction_-_problem_solution'>Problem Solution</h2>
<p>
We have chosen to create a game using the tower defense genre, as this requires somewhat less work and graphics than many other genres, as well as having a lot of possible parameters that can be tweaked in order to adapt the contents of the game (henceforth: gameplay). The game uses a modified stochastic hill climbing algorithm together with some user feedback after each game, to adapt itself towards the individual player.
</p>

<h1 id='shc'>Stochastic hill climbing</h1>

<p>
A hill climbing algorithm is an iterative improvement algorithm, searching for a local maximum. It tries to maximize a function f(X), where X could be a node, state, position or, in our case, a vector of parameters. It compares neighboring nodes to the one it is standing on, and checks if they are an improvement on f(X). If one of the other nodes is improving the situation, then the algorithm moves to the new node, commonly the best node, and repeats the process. The process is repeated until no more improvements can be found, thus the algorithm has found a local maximum. <a href='#reference_6' title='Russell, S. J., & Norvig, P. (1995), <i>Artificial Intelligence: A Modern Approach</i>. Upper Saddle River, NJ: Prentice Hall'>[6]</a>
</p>

<div id='hclocalmaximum' class='figure'><img src='Hill_Climbing_Local_Maximum.png' alt='A function that has a local maximum' title='A function that has a local maximum'><div class='caption'>A function that has a local maximum</div></div>
<div id='hcflat' class='figure'><img src='Hill_Climbing_Flat.png' alt='A function that is too flat to search on' title='A function that is too flat to search on'><div class='caption'>A function that is too flat to search on</div></div>
<div id='hcsteep' class='figure'><img src='Hill_Climbing_Steep.png' alt='A function that is very steep' title='A function that is very steep'><div class='caption'>A function that is very steep</div></div>

<p>
One issue with this algorithm, is that it can become stuck on a local maximum, which may not be the global maximum, as in <a href='#hclocalmaximum' class='figref'>this figure</a>. One way to reduce the probability of this to happen, is to allow the algorithm to jump larger distances each jump, or to make sure that the landscape is convex. Another issue shown by <a href='#hcflat' class='figref'>this figure</a> is that the search area may be flat, that is, each node is as good as all its neighbors. In this case, any jump will not bring any improvement. A third issue in <a href='#hcsteep' class='figref'>this figure</a> is that a node may be lying on a very steep ridge, that is, the 'area' of parameters that give a good node is very small, and can thus be hard to find. <a href='#reference_6' title='Russell, S. J., & Norvig, P. (1995), <i>Artificial Intelligence: A Modern Approach</i>. Upper Saddle River, NJ: Prentice Hall'>[6]</a>
</p>

<p>
There are different variants of hill climbing algorithms, with different ways of deciding where and when to jump. The stochastic hill climbing algorithm, closely resembling simulated annealing, chooses a position at random, then evaluates whether it is an improvement, and if it is, jumps to the new position. If the new position is not an improvement, it will go back to the last one. With stochastic hill climbing, it may be wise to set a specific maximum jump distance, and let this decrease over time. This allows the algorithm to converge or settle on a position after some time. <a href='#reference_6' title='Russell, S. J., & Norvig, P. (1995), <i>Artificial Intelligence: A Modern Approach</i>. Upper Saddle River, NJ: Prentice Hall'>[6]</a>
</p>

<h2 id='stochastic_hill_climbing_-_stochastic_hill_climbing_example'>Stochastic hill climbing example</h2>

<p>
Here is an example for how to use stochastic hill climbing for how to find the maximum value of the function f(X) = 2 - X<sup>2</sup>. which has a maximum value of 2. We initialize the maximum jump distance (in x-direction) to a value of 1.0, and let this decrease by 0.1 with each jump.
</p>

<div id='hcex1' class='figure'><img src='Hill_Climbing_Example_1.png' alt='The startpoint for the search' title='The startpoint for the search'><div class='caption'>The startpoint for the search</div></div>
<div id='hcex2' class='figure'><img src='Hill_Climbing_Example_2.png' alt='The first jump' title='The first jump'><div class='caption'>The first jump</div></div>
<div id='hcex3' class='figure'><img src='Hill_Climbing_Example_3.png' alt='An attempted jump' title='An attempted jump'><div class='caption'>An attempted jump</div></div>
<div id='hcex4' class='figure'><img src='Hill_Climbing_Example_4.png' alt='Achieving global maximum' title='Achieving global maximum'><div class='caption'>Achieving global maximum</div></div>
<div id='hcex5' class='figure'><img src='Hill_Climbing_Example_5.png' alt='Further jumps are discarded' title='Further jumps are discarded'><div class='caption'>Further jumps are discarded</div></div>

<p>
This is a short example of how stochastic hill climbing will eventually find the local, or global, maximum on a graph. This example is very short, compared to how many jumps it would normally take, but this is actually possible.
</p>

<p>
With a starting maximum jump distance of 1.0, decreasing by 0.1 with each jump, the algorithm will have converged after ten jumps, hopefully at an acceptable position. In a game setting, it may be wise to let the maximum jump distance never decrease to zero, because it can make the game feel more lively.
</p>

<h1 id='solution'>Solution</h1>

<p>
In this chapter we will talk about our solution which is an implementation of the Stochastic Hillclimbig algorithm along with a few features needed to adapt it for our use. We work with the paramteres listed in <a href='#app_1' class='chapref_1'>Appendix I - Parameters</a>.
</p>

<h2 id='solution_-_algorithm'>Algorithm</h2>

<div id='pseudoalgorithm' class='figure'><img src='pseudoAlgorithm.png' alt='Pseudo-code for the algorithm.' title='Pseudo-code for the algorithm.'><div class='caption'>Pseudo-code for the algorithm.</div></div>

<div id='algorithmexample' class='figure'><img src='algorithm.png' alt='The flow of our algorithm.' title='The flow of our algorithm.'><div class='caption'>The flow of our algorithm.</div></div>

<p>
As indicated in the figure we start with set values for all parameters, which is a prior we have found to give a decent game. After playing a game the user gives feedback we use to create the metric is "How fun was this game?" and "How difficult was this game?". The first one presents the user with three hearts, and for each heart selected we roll a die from one to ten one time. This number is multiplied with a multiplier which increases as more games are played. This is to not end up stuck in a place just because the feedback received a high random value.
</p>

<h2 id='solution_-_litt_lang_setning__som_er_en_hel_paragraf_'>Litt lang setning, som er en hel paragraf?</h2>
<p>
After the metric has been created we compare it with the currently best known metric, and if we find that the new metric is better we save these as the best known metric conintue to jump from there, else we restore the parameters from the game where we received the best metric.
</p>

<div id='pseudorelations' class='figure'><img src='pseudoRelations.png' alt='Pseudo-code for jumping of relations' title='Pseudo-code for jumping of relations'><div class='caption'>Pseudo-code for jumping of relations</div></div>

<p>
We randomly increase or decrease the parameters with parameters from zero up to a max jump distance, and let the user play again and repeat the process. The max jump distance decreases each time we find a better game, and thus we attempt to converge at a point where the user enjoys the game. Perceived fun is fleeting though, and if the user grows tired of an area he might start to rate it lower, and thus when a user gives a game the lowest rating we increase the max jump distance, to enable users to find new games.
</p>

<p>
The main feature we have implemented to adapt the stochastic hillclimbing algorithm to work with our parameters is relations. We needed to change the game, while not necessarily changing the difficulty. To do this we decided to put most of the parameters in relations. We do not change all parameters individually when jumping, but cycle through all relations and jump parameter one, and parameter two is changed as defined by the relation.
</p>

<div id='relationsexample' class='figure'><img src='relationsFun.png' alt='Basic relations example.' title='Basic relations example.'><div class='caption'>Basic relations example.</div></div>

<p>
The figure above illustrate how relations work. We have the relation GlobelMonsterHP->GlobalMonsterSpeed, when one goes up, the other one goes down proportionally. This may also be between two parameters which will change in the same direction as also seen in <a href='#relationsexample' class='figref'>this figure</a> where GlobalMonsterHp->TEDamage(Tower Damage) and both increase. As you may have noted, parameters can also be in more than one relation, thus when GlobalMonsterHP changes, it affects both GlobalMonsterSpeed and TEDamage.
</p>

<div id='difficultyexample' class='figure'><img src='difficulty.png' alt='Difficulty does not change in relations.' title='Difficulty does not change in relations.'><div class='caption'>Difficulty does not change in relations.</div></div>

<p>
We also get feedback on the difficulty, while this is not the main focus of this report, it does indicate something about the user. Since a game that is to easy or to hard is not fun, we found that we needed to implement some sort of difficulty scalign as well. We have implemented Stochastic Hillclimbing for the difficulty. Here however we just have parameters, and since the metric here in the sense of a graph would be "Too Low"(Easy), "Perfect" and "Too High"(Difficult), it is quite easy to guide the search and make it less random.
</p>

<h1 id='game_description'>Game Description</h1>
<p>
This chapter gives some pictures and a short description of our game, as well as some general information about the game genre, namely tower defense.
</p>

<h2 id='game_description_-_genre'>Genre</h2>
<p>
The game we created to demonstrate our algorithm is a real-time strategy game, more precisely it would be refered to as a tower defense game. The goal of the game is to build tower tactically accross a map to prevent computer controlled enemies from reaching the other side.
</p>

<h2 id='game_description_-_our_game'>Our game</h2>
<p>
Our game is very similar to classic tower defense games, in that the player has to stop different kinds of enemies from reaching the destination on their path, by using different kinds of towers. Our game differs slightly from other tower defense games on several points.
</p>

<p>
There are no scripted or static levels, since each game is a step closer towards the player's 'ideal game', that is, the game that is perceived as the most fun. Other than that the game learns after each level, the player has nothing that is carried over to the next game, such as tower access, special items or game progress in general. The player simply plays successive games until he or she quits.
</p>

<p>
The game has modular towers and enemies. This is not necessarily new to the tower defense genre, as not all tower defense games may have pre-defined enemies and towers, but this is something that can be used in order to adapt the game towards personal preferences. (Guided) Randomly generated maps. Not necessarily new to the genre either, but is another useful technology that can be used to adapt the game to the player. Note that our game did not use this for game adaption, only to make the game seem less static.
</p>

<h1 id='testing'>Testing</h1>
<p>
Our testing is split into two parts. The first part contains two case tests of the algorithm, and the second part contains tests from our fellow students and friends.
</p>

<h2 id='testing_-_difficulty_testing'>Difficulty testing</h2>
<p>
This is how our algorithm performed.
</p>

<h2 id='fun_testing'>Fun testing</h2>
<p>
After we finished the game, it was mainly sent to friends at the university. They were told to test the game for as long as they wanted, and when they were finished, they sent us a logfile containing some information about their games. An example logfile can be found in <a href='#app_2' class='chapref_1'>Appendix II - Example Logfile</a>. They were also asked to rate how fun they thought the game was in total.
</p>

<div id='testing' class='table'>
<table>
<tr><td>"Subject"</td><td>"Estimated game experience"</td><td>"Games played"</td><td>"Rating"</td></tr>
<tr><td>1</td><td>"High"</td><td>6</td><td>10</td></tr>
<tr><td>2</td><td>"Medium"</td><td>2</td><td>8</td></tr>
<tr><td>3</td><td>"High"</td><td>10</td><td>5</td></tr>
<tr><td>4</td><td>"High"</td><td>6</td><td>7</td></tr>
<tr><td>5</td><td>"Medium"</td><td>8</td><td>8</td></tr>
<tr><td>6</td><td>"High"</td><td>17</td><td>5</td></tr>
</table>
<div class='caption'>Test results for fun testing</div>
</div>

<p>
As you can see in <a href='#testing' class='tableref'>this table</a>, the game was played 8.17 times on average, given a rating of 7.17 on average. This is quite high values, which is something we consider to be good test results for the game itself.
</p>

<p>
Four out of the six subjects were also asked to rate the game at the beginning and at the end, in order to say something about whether the game converged at a better position or not.
</p>

<div id='testing2' class='table'>
<table>
<tr><td>"Subject"</td><td>"Estimated game experience"</td><td>"Games played"</td><td>"Start rating"</td><td>"End rating"</td></tr>
<tr><td>1</td><td>"High"</td><td>6</td><td>10</td><td>3</td></tr>
<tr><td>2</td><td>"Medium"</td><td>2</td><td>8</td><td>7</td></tr>
<tr><td>3</td><td>"High"</td><td>10</td><td>5</td><td>6</td></tr>
<tr><td>4</td><td>"High"</td><td>6</td><td>7</td><td>5</td></tr>
</table>
<div class='caption'>Before-and-after test results</div>
</div>

<p>
Three out of four rated the game better before the algorithm changed the game, than after, which is not actually very positive. However, as we note in chapter 9, <a href='#discussion' class='chapref_1'>Discussion</a>, we believe that some of the parameters are having too big an impact on the game, resulting in poorer test results.
</p>

<h1 id='discussion'>Discussion</h1>

<p>
In this chapter, we discuss three topics. First we discuss the results from the fun testing, then the results from the difficulty or case testing, and lastly we discuss some other observations noted during the development process.
</p>

<h2 id='discfun'>Discussing the fun testing</h2>
<p>
When looking at the fun testing results, we see that our game was generally rated fun, with an average of 7.17 our of 10. But since our testers were mainly friends and fellow students, we were expecting to receive rather high values, as they did not want to make us feel bad. But a 7.17 out of 10 is not actually bad for the game itself, as much of the game content, such as audio and graphics, was made without a budget. But a difficult aspect of this project, is that it is hard to measure whether something is fun or not. Our main feedback for how well the game worked is the ratings from players, and from that we are satisfied with how fun the game was perceived to be, but even if the game was characterized 10 out of 10, the test results could mostly reflect the game and its contents, and not tell us much about the algorithm itself.
</p>

<p>
The second part of the fun testing results tells us more about the algorithm itself. The results reveal that the subjects thought the game was actually becoming worse over time, instead of maximizing fun. As mentioned in <a href='#fun_testing' class='chapref_2'>Fun testing</a>, we believe that two of our parameters, named "SuperChance" and "DiggerChance", see <a href='#app_2' class='chapref_1'>Appendix II - Example Logfile</a>, should have been normalized. As of now, they have too big an impact on the game, because their values are varying too much each jump. To the best of our knowledge, this is a result of our modified algorithm, which we believe can be fixed by having multiple specialized algorithms, instead of a central one. Another solution could be to only alter a single parameter each jump, because the algorithm would then be more sure about what the player enjoyed after each jump. This latter solution would make the algorithm work more slowly, which is maybe a too valuable trade-off.
</p>

<h2 id='discussion_-_discussing_the_difficulty_testing'>Discussing the difficulty testing</h2>
<p>
The difficulty test results are good, in that the algorithm is able to change the difficulty based on the feedback it receives, relatively quickly. However, the algorithm we use for difficulty scaling is not the same as the one we use for maximizing fun. Since the difficulty can only be either too difficult, perfect or too easy, it is easier to scale difficulty, than to maximize fun.
</p>

<h2 id='observations'>Other observations</h2>
<p>
Another problem we have noticed during the development process, is that the jumps themselves may be too subtle for a player to notice when jump distance shortens. The algorithm requires positive feedback when it goes in a direction the player likes, but if the change is not noticable the player may give it the same score, thus have a decent chance of ending up jumping from his old game each jump. This issue is similar to the one in chapter 5, <a href='#shc' class='chapref_1'>Stochastic hill climbing</a>, <a href='#hcflat' class='figref'>this figure</a>.
</p>

<p>
Lastly, we also noticed that the tower defense genre may not be well suited for creating an adaptive game. This is mainly because of the three following reasons. Firstly, the core game elements are rather static, which makes it difficult to make the game look and feel adaptive to the player. A different genre, such as the platformer, with game a example like Super Mario Bros. <a href="http://mario.nintendo.com/">[7]</a>. Secondly, the parameters in a tower defense game are very tightly knit together, in order to keep the game difficulty in balance. It is difficult to map how they all fit together, which makes it difficult for our algorithm to jump randomly to a new position, while still maintaining mentioned balance. Thirdly, the fun factor in a tower defense game is often related to the feeling of accomplishment. For instance, this feeling may occur when the player has lost a couple of games at the same challenge, and finally is able to beat the game. Since the game adapts itself to the player, thus is never the same, some would feel that their accomplishment is diminished.
</p>

<h1 id='conclusion'>Conclusion</h1>
<p>
Although some of the test results came out negative, we still believe that the concept of adapting a game to an individual is something that can be done, in order to maximize fun. The game itself was considered fun, and we believe that some of the reason lays in the variety of the game, caused by its adaptivity. But in order to be able to maximize fun, the algorithm needs to become more refined, and could work much better if we fetch specialized information, indicating what the player really enjoyed. This information could then be used to let the algorithm do a more guided search to find out where to jump next, and not do a completely random jump. On the other hand, the difficulty scaling, works very well, and is something that we can re-use in later projects, such as for E-learning purposes.
</p>

<p>
As noted in <a href='#observations' class='chapref_2'>Other observations</a>, the 'flat-issue' that can be experienced with hill-climbing in general, also occurred at some point during our own development process. In order to combat this, an adaptive game itself needs to have much and varied game content, so the different games is felt different by the player. The player can then give better feedback to how the game was, and whether the algorithm should jump from a new location or not.
</p>

<p>
We would also probably have gotten a better result by choosing a different game genre than tower defense. When the game uses a stochastic hill climbing algorithm relying on too many parameters, it is unlikely that all will go in an optimal direction at once. As mentioned in the second part of <a href='#discfun' class='chapref_2'>Discussing the fun testing</a>, we believe that if the game had used multiple specialized algorithms, which examines fewer parameters at a time, the total algorithm could have been more precise in its jumps. If specialized enough, one of the algorithms could also automatically detect feedback through how a player plays, rather than requiring a questionnaire at the end.
</p>

<p>
If we do stochastic hill climbing based on metrics created based on how the player is playing, on few parameters for each part of the algorithm, we believe that we could get much better results. However, as this has been, to the best of our knowledge, the first venture into creating games which adapt based on fun, we are quite happy with our result. 
</p>

<p>
SPØRRE ROBIN
</p>

<h1 id='future_work'>Future Work</h1>

<p>
The algorithm works ok, but it needs to be more refined. We believe that with some work refining the algorithm, and doing more testing with different sensors to see if certain feedback can be interprented to liking certain things in the game, we can create a great algorithm to maximize fun even in games with many parameters.
</p>

<p>
We would like to try to implement this sort of algorithm in a game related to e-learning. Currently one of the problems with e-learning games is that they feel to much like learning and to little like games. If we could be able to create a game which can maximize the fun a player has, while also scaling the difficulty appropriately we believe we could create an effective learning tools for many skills.
</p>

<p>
With a more refined algorithm we believe this could be highly useful in a game, however it needs more sensors or ways to detect which parameters the players are satisfied with and not. There are also interesting applications for this sort of algorithm in E-learning, if we can detect how to make an e-learning game fun for a player and also scale the difficulty to their ability we may create an effective game for learning.
</p>



<h1 id='references'>References</h1>

<p>
IEEE, ACM, Springer
</p>

<div>
<span id='reference_1'>[1] Tavangarian, D., Leypold, M. E., Nölting, K., Röser, M., & Voigt, D. (2004). Is e-learning the Solution for Individual Learning. <i>Electronic Journal of E-learning</i>, 2(2), 273-280.</span><br>
<span id='reference_2'>[2] Marczewski, A. (2012). <i>Gamification: A Simple Introduction.</i> Andrzej Marczewski.</span><br>
<span id='reference_3'>[3] Zichermann, G., & Cunningham, C. (2011). <i>Gamification by design: Implementing game mechanics in web and mobile apps.</i> O'Reilly Media.</span><br>
<span id='reference_4'>[4] Huotari, K., & Hamari, J. (2012, October). Defining gamification: a service marketing perspective. In <i>Proceeding of the 16th International Academic MindTrek Conference</i> (pp. 17-22). ACM.</span><br>
<span id='reference_5'>[5] Spronck, P., Sprinkhuizen-Kuyper, I., & Postma, E. (2004). Difficulty scaling of game AI. In <i>Proceedings of the 5th International Conference on Intelligent Games and Simulation (GAME-ON 2004)</i> (pp. 33-37).</span><br>
<span id='reference_6'>[6] Russell, S. J., & Norvig, P. (1995), <i>Artificial Intelligence: A Modern Approach</i>. Upper Saddle River, NJ: Prentice Hall</span><br>
<a id='reference_7' href="http://mario.nintendo.com/">[7] http://mario.nintendo.com/</a><br>
</div>


<h1 id='app_1' class='notoc'>Appendix I - Parameters</h1>

<p>
Following is a list of the parameters the game changes, and their function.
</p>

<ul>
<li>GlobalMonsterHP - Affects the HP of all enemies.</li>
<li>TEDotDamage - Affects the damage of each tick for the damage over time tower.</li>
<li>TEDotTicks - Affects how many ticks of damage the damage of time tower does.</li>
<li>TESlowPercentage - Affects the amount of slow the frost tower causes to an enemy.</li>
<li>TESlowDuration - Affects the duration of the slow from the frost tower.</li>
<li>GlobalReloadTime - Affects reload time for all towers.</li>
<li>TEDamage - Affects damage for all towers.</li>
<li>GlobalBuildCost - Affects cost to build each tower.</li>
<li>GlobalMonsterSpeed - Affects the speed of all enemies.</li>
<li>GlobalMonsterGoldYield - Affects how much gold each enemy yields.</li>
<li>GlobalTowerRange - Affects how far towers can shoot.</li>
<li>DiggerChance - Affects how often an enemy will be a digger.</li>
<li>SuperChance - Affects how often an enemy will have one or more super effects.</li>
<li>EarthquakeChance - Affects how often earthquakes are enabled and disabled.</li>
<li>EarthquakeChanceInGame - Affects how often there is an earthquake when enabled.</li>
</ul>

<h1 id='app_2' class='notoc'>Appendix II - Example Logfile</h1>

<p>
This is an example log file as generated when someone plays the game.
</p>

<p>
Game number 1 - at May 23, 2013 12:33:20 PM - Game WON<br>
Lives left        : 10/10<br>
Gold left         : 90/100<br>
Earthquake count  : 9<br>
Shots fired       : 607
</p>
<p style='text-align: center'>-Tower information---</p>
<p>
Towers built      : 12<br>
Upgrades bought   : 0<br>
Towers sold       : 0<br>
Towers destroyed  : 0<br>
Earthquake proofs : 0<br>
Arrow towers      : 1<br>
Frost towers      : 2<br>
Cannon towers     : 2<br>
Flame towers      : 0<br>
Laser towers      : 4<br>
Burning towers    : 3
</p>
<p style='text-align: center'>-Metric and jump information---</p>
<p>
Hearts feedback        : 0<br>
Difficulty feedback    : 0<br>
Last metric            : 0.0<br>
Challenger metric      : 0.0<br>
Max jump distance      : 0.4<br>
Player Level           : 0.0<br>
Game length multiplier : 1.0
</p>
<p style='text-align: center'>-Enemy information---</p>
<p>
Total enemies killed : 45/45<br>
Basic enemies killed : 14/15<br>
Fast enemies killed  : 14/15<br>
Tough enemies killed : 17/18<br>
Diggers killed       : 0/0<br>
Total supers killed  : 0/0<br>
Super fast   killed  : 0/0<br>
Super tough  killed  : 0/0<br>
Super shield killed  : 0/0<br>
Super invis  killed  : 0/0
</p>
<p style='text-align: center'>-Parameters---</p>
<p>
TEDotDamage:             1.0         Min: 0.1   Max: 3.0<br>
TEDamage:                1.0         Min: 0.01  Max: 10.0<br>
DiggerChance:            0.2         Min: 0.0   Max: 1.0<br>
EarthquakeChance:        0.2         Min: 0.0   Max: 1.0<br>
GlobalMonsterHP:         1.0         Min: 0.1   Max: 3.0<br>
SuperChance:             0.2         Min: 0.0   Max: 1.0<br>
TESlowDuration:          1.0         Min: 0.1   Max: 3.0<br>
EarthquakeChanceInGame:  0.2         Min: 0.1   Max: 0.9<br>
GlobalReloadTime:        1.0         Min: 0.1   Max: 3.0<br>
GlobalTowerRange:        1.0         Min: 0.1   Max: 10.0<br>
GlobalMonsterGoldYield:  1.0         Min: 0.1   Max: 3.0<br>
GlobalMonsterSpeed:      1.0         Min: 0.1   Max: 10.0<br>
TESlowPercentage:        1.0         Min: 0.1   Max: 1.4<br>
GlobalBuildCost:         1.0         Min: 0.1   Max: 3.0<br>
TEDotTicks:              1.0         Min: 0.1   Max: 3.0
</p>

<p>
Game number 2 - at May 23, 2013 12:34:49 PM - Game LOST<br>
Lives left        : 0/10<br>
Gold left         : 21/110<br>
Earthquake count  : 0<br>
Shots fired       : 324
</p>
<p style='text-align: center'>-Tower information---</p>
<p>
Towers built      : 11<br>
Upgrades bought   : 0<br>
Towers sold       : 0<br>
Towers destroyed  : 3<br>
Earthquake proofs : 0<br>
Arrow towers      : 2<br>
Frost towers      : 1<br>
Cannon towers     : 2<br>
Flame towers      : 1<br>
Laser towers      : 3<br>
Burning towers    : 2
</p>
<p style='text-align: center'>-Metric and jump information---</p>
<p>
Hearts feedback        : 0<br>
Difficulty feedback    : 0<br>
Last metric            : 0.0<br>
Challenger metric      : 5.0<br>
Max jump distance      : 0.25599998<br>
Player Level           : 1.0<br>
Game length multiplier : 1.2
</p>
<p style='text-align: center'>-Enemy information---</p>
<p>
Total enemies killed : 22/45<br>
Basic enemies killed : 8/12<br>
Fast enemies killed  : 9/21<br>
Tough enemies killed : 5/11<br>
Diggers killed       : 0/3<br>
Total supers killed  : 0/3<br>
Super fast   killed  : 0/2<br>
Super tough  killed  : 0/3<br>
Super shield killed  : 0/1<br>
Super invis  killed  : 0/1
</p>
<p style='text-align: center'>-Parameters---</p>
<p>
TEDotDamage:             1.0799435   Min: 0.1   Max: 3.0<br>
TEDamage:                0.95508564  Min: 0.01  Max: 10.0<br>
DiggerChance:            0.4         Min: 0.0   Max: 1.0<br>
EarthquakeChance:        0.3330284   Min: 0.0   Max: 1.0<br>
GlobalMonsterHP:         1.1467683   Min: 0.1   Max: 3.0<br>
SuperChance:             0.4         Min: 0.0   Max: 1.0<br>
TESlowDuration:          1.2593029   Min: 0.1   Max: 3.0<br>
EarthquakeChanceInGame:  0.3         Min: 0.1   Max: 0.9<br>
GlobalReloadTime:        1.1283836   Min: 0.1   Max: 3.0<br>
GlobalTowerRange:        1.1272081   Min: 0.1   Max: 10.0<br>
GlobalMonsterGoldYield:  1.1011007   Min: 0.1   Max: 3.0<br>
GlobalMonsterSpeed:      0.8071418   Min: 0.1   Max: 10.0<br>
TESlowPercentage:        0.74069715  Min: 0.1   Max: 1.4<br>
GlobalBuildCost:         1.1011007   Min: 0.1   Max: 3.0<br>
TEDotTicks:              0.92005646  Min: 0.1   Max: 3.0
</p>
</body></html>