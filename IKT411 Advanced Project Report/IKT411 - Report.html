<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN" "http://www.w3.org/TR/html4/strict.dtd">
<html>
<head>
<title>Title</title>
<link href="style.css" rel="stylesheet" type="text/css">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
</head>
<body>












<p style='text-align: center'><img src="http://www.uia.no/no/content/download/79969/1326369/file/UiA+logo+engelsk.jpg" width="50%" height="50%" alt="UiA Logo"></p>
<p><br></p>
<p><br></p>

<div style="font-size: 16pt; text-align: center"><b>Maximizing Fun in An Adaptive Tower Defense Game using Stochastic Hill Climbing</b></div>

<p><br></p>
<p style="text-align: center">By<br>
<br>Jon Vegard Jansen, Robin Tollisen
</p>
<p style='text-align: center'>Supervisor: Sondre Glimsdal<br><br></p>
<p style='text-align: center'><b>Project report for IKT411 in Spring 2013</b><br><br></p>
<p style="text-align: center">Faculty of Engineering and Science
<br>University of Agder
<br>Grimstad, 7th of June
</p>

<p style='text-align: center'>Status: Final</p>
<p><b>Keywords:</b> E-learning, gamification, unsupervised online learning, stochastic hill climbing, maximize fun<br></p>

<p><b>Abstract:</b><br>Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.</p>


<h1 id='toc' class='notoc'>Table of contents</h1>
<p>
"Husk class='notoc'"
</p>

<div>
<a href='#intro' class='toc_1'>Introduction</a><br>
<a href='#background' class='toc_2'>Background</a><br>
<a href='#introduction_-_problem_statement' class='toc_2'>Problem Statement</a><br>
<a href='#introduction_-_problem_solution' class='toc_2'>Problem Solution</a><br>
<a href='#introduction_-_report_outline' class='toc_2'>Report Outline</a><br>
<a href='#adaptive_tower_defense' class='toc_1'>Adaptive Tower Defense</a><br>
<a href='#adaptive_tower_defense_-_a_short_overview' class='toc_2'>A short overview</a><br>
<a href='#parameters' class='toc_2'>Parameters and Adaptivity</a><br>
<a href='#adaptive_tower_defense_-_adaptivetd_vs__similar_games' class='toc_2'>AdaptiveTD vs. similar games</a><br>
<a href='#adaptive_tower_defense_-_tools_and_publishing' class='toc_2'>Tools and publishing</a><br>
<a href='#shc' class='toc_1'>Stochastic hill climbing</a><br>
<a href='#shce' class='toc_2'>Stochastic hill climbing example</a><br>
<a href='#solution' class='toc_1'>Solution</a><br>
<<<<<<< HEAD
<a href='#solution_-_algorithm' class='toc_2'>Algorithm</a><br>
=======
<a href='#algorithm' class='toc_2'>Algorithm</a><br>
>>>>>>> Report work before submit
<a href='#solution_-_litt_lang_setning__som_er_en_hel_paragraf_' class='toc_2'>Litt lang setning, som er en hel paragraf?</a><br>
<a href='#testing' class='toc_1'>Testing</a><br>
<a href='#testing_-_difficulty_testing' class='toc_2'>Difficulty testing</a><br>
<a href='#fun_testing' class='toc_2'>Fun testing</a><br>
<a href='#rpt' class='toc_3'>Real Playtests</a><br>
<a href='#testing_-_fun_testing_-_case_tests' class='toc_3'>Case tests</a><br>
<a href='#discussion' class='toc_1'>Discussion</a><br>
<a href='#discfun' class='toc_2'>Discussing the fun testing</a><br>
<a href='#discussion_-_discussing_the_difficulty_testing' class='toc_2'>Discussing the difficulty testing</a><br>
<a href='#observations' class='toc_2'>Other observations</a><br>
<a href='#conclusion' class='toc_1'>Conclusion</a><br>
<a href='#futurework' class='toc_1'>Future Work</a><br>
<a href='#references' class='toc_1'>References</a><br>
</div>


<h1 id='table_of_figures' class='notoc'>Table of figures</h1>
<p>
"Husk class='notoc'"
</p>

<div>
<a href='#tdimg' class='figtoc'>Left: AdaptiveTD. Right: A tower defense game called Fieldrunners <a href="http://wp.appadvice.com/wp-content/uploads/2010/04/IMG_0005.jpg">[6]</a></a><br>
<a href='#enemies' class='figtoc'>Enemies from AdaptiveTD</a><br>
<a href='#towers' class='figtoc'>Towers from AdaptiveTD</a><br>
<a href='#gold' class='figtoc'>Gold is represented by the number next to this symbol</a><br>
<a href='#colordifference' class='figtoc'>The level of enemy health (difficulty) is reflected in the background color</a><br>
<a href='#sliderbars' class='figtoc'>Sliderbars that indicate the current level of enemy health, enemy speed and tower damage</a><br>
<a href='#relations' class='figtoc'>Parameters in relation to each other</a><br>
<a href='#super' class='figtoc'>A tough enemy who has been given extra, super abilities an enemy can have at a time: More health, more speed, invisibility and impossible to harm</a><br>
<a href='#digger' class='figtoc'>The digger enemy is a difficult opponent</a><br>
<a href='#phone' class='figtoc'>AdaptiveTD on a mobile device</a><br>
<a href='#pseudoshc' class='figtoc'>Pseudo-code for Stochastic Hillclimbing, as done in @chapref(shce).</a><br>
<a href='#hclocalmaximum' class='figtoc'>A function that has a local maximum</a><br>
<a href='#hcflat' class='figtoc'>A function that is too flat to search on</a><br>
<a href='#hcsteep' class='figtoc'>A function that is very steep</a><br>
<a href='#hcex1' class='figtoc'>The startpoint for the search</a><br>
<a href='#hcex2' class='figtoc'>The first jump</a><br>
<a href='#hcex3' class='figtoc'>An attempted jump</a><br>
<a href='#hcex4' class='figtoc'>Achieving global maximum</a><br>
<a href='#hcex5' class='figtoc'>Further jumps are discarded</a><br>
<a href='#pseudoalgorithm' class='figtoc'>Pseudo-code for the algorithm.</a><br>
<a href='#algorithmexample' class='figtoc'>The flow of our algorithm.</a><br>
<a href='#pseudorelations' class='figtoc'>Pseudo-code for jumping of relations</a><br>
<a href='#relationsexample' class='figtoc'>Basic relations example.</a><br>
<a href='#difficultyexample' class='figtoc'>Difficulty does not change in relations.</a><br>
<a href='#reloadfun' class='figtoc'>Plot of the case tests for Global Reload time.</a><br>
<a href='#avgreloadfun' class='figtoc'>Average values from the case tests for Global Reload time.</a><br>
<a href='#postreloadfun' class='figtoc'>Plot of the case tests after one heart not chosen.</a><br>
<a href='#avgreloadpostreload' class='figtoc'>Average Reload time for all playthroughs for both versions.</a><br>
<a href='#reloaddamage' class='figtoc'>Plot of how global reload and tower damage changed over time.</a><br>
</div>


<h1 id='table_of_tables' class='notoc'>Table of tables</h1>
<p>
"Husk class='notoc'"
</p>

<div>
</div>


<h1 id='intro'>Introduction</h1>
<p>
Today, there exists more commercial video and computer games (henceforth: games) than ever before, and the number of persons owning a smart-phone or personal computer is increasing. Many students and pupils neglect their studies in favor of watching television or playing games, maybe because they consider it more fun. We believe that through the use of E-learning and gamification, which enhances traditional learning methods with elements from games, it is possible to make any learning process more fun, resulting in more interested students and better grades.
</p>

<p>
As each student is unique, we believe that they also have different learning methods that work best for them, which is why we have chosen to look into adaptive games. In this project we research whether a game can be made, such that it adapts to each player on the fly.
</p>

<h2 id='background'>Background</h2>
<p>
A lot of research has already been done on the area of E-learning, and there exists multiple definitions. We have chosen to use the following one, because it emphasizes the individual student, which goes hand in hand with individual adaption of application.
</p>

<i>"We will call e-Learning all forms of electronic supported learning and teaching, which ... aim to effect the construction of knowledge with reference to individual experience, practive and knowledge of the learner..."</i> <a href='#reference_1' title='Tavangarian, D., Leypold, M. E., Nölting, K., Röser, M., & Voigt, D. (2004). Is e-learning the Solution for Individual Learning. <i>Electronic Journal of E-learning</i>, 2(2), 273-280.'>[1]</a>.

<p>
Gamification is a concept that has been around for a long time, and has increased with popularity since 2010. <a href='#reference_2' title='Marczewski, A. (2012). <i>Gamification: A Simple Introduction.</i> Andrzej Marczewski.'>[2]</a> <a href='#reference_3' title='Zichermann, G., & Cunningham, C. (2011). <i>Gamification by design: Implementing game mechanics in web and mobile apps.</i> O'Reilly Media.'>[3]</a>. We present the two following definitions, as we think both of them show that gamification can be used well in conjunction with E-learning.
</p>
 
<i>"The process of game-thinking and game mechanics to engage users and solve problems."</i> <a href='#reference_3' title='Zichermann, G., & Cunningham, C. (2011). <i>Gamification by design: Implementing game mechanics in web and mobile apps.</i> O'Reilly Media.'>[3]</a>.<br/>
<br/>
<i>"A process of enhancing a service with affordances for gameful experiences in order to support user's overall value creation."</i> <a href='#reference_4' title='Huotari, K., & Hamari, J. (2012, October). Defining gamification: a service marketing perspective. In <i>Proceeding of the 16th International Academic MindTrek Conference</i> (pp. 17-22). ACM.'>[4]</a>.

<p>
The latter definition is directed towards service marketing, but if one reads 'service' as 'learning process' and 'user's overall value creation' as 'learning outcomes', we believe that gamification is something that could be used together with both tradition learning methods and E-learning.
</p>

<p>
While we believe in the concept of gamification, for this project we will create our own game to test an algorithm for adaptive games.
</p>

<p>
If one is to create a game that is meant for learning purposes, it is important to note that the game needs to be fun. <a href='#reference_3' title='Zichermann, G., & Cunningham, C. (2011). <i>Gamification by design: Implementing game mechanics in web and mobile apps.</i> O'Reilly Media.'>[3]</a>. If a game is not fun, it will not be able to educate either, because players lose interest in games the same way as students lose interest lectures, should they be boring. This is why it is important to figure out how it is possible to maximize the fun in any kind of game, thus keeping the interest of players. Since games appeal to a wide variety of players, the perceived level of fun may often vary among its players, due to personal preferences. In order to accomodote for such varying preferences, traditional games have often implemented several levels of difficulty the player may choose from, as well as providing the player with several settings or options for how they want the game to behave. When it comes to difficulty, other work has already been done on how to scale and adapt this to the level of player, in order to make even games, but in order to make a game fun, we believe that more than difficulty needs to adapt to individual preferences, thus more aspects of a game should be able to change on the fly. <a href='#reference_5' title='Spronck, P., Sprinkhuizen-Kuyper, I., & Postma, E. (2004). Difficulty scaling of game AI. In <i>Proceedings of the 5th International Conference on Intelligent Games and Simulation (GAME-ON 2004)</i> (pp. 33-37).'>[5]</a>.
</p>

<h2 id='introduction_-_problem_statement'>Problem Statement</h2>
<p>
Our project is to research whether it is possible to create a game, that uses an unsupervised online learning algorithm, which will adapt the game to the user's preferences based on limited user feedback.
</p>

<h2 id='introduction_-_problem_solution'>Problem Solution</h2>
<p>
We have chosen to create a game using the tower defense genre, as this requires somewhat less work and graphics than many other genres, as well as having a lot of possible parameters that can be tweaked in order to adapt the contents of the game (henceforth: gameplay). The game uses a modified stochastic hill climbing algorithm together with some user feedback after each game, to adapt itself towards the individual player. We call the game Adaptive Tower Defense, and abbrieviate it AdaptiveTD.
</p>

<h2 id='introduction_-_report_outline'>Report Outline</h2>
<p>
Quick and short and concrete
</p>

<h1 id='adaptive_tower_defense'>Adaptive Tower Defense</h1>
<p>
This chapter gives some pictures and a short description of AdaptiveTD, as well as some general information about the game genre, namely tower defense.
</p>

<div id='tdimg' class='figure'><img src='Tower_Defense.png' alt='Left: AdaptiveTD. Right: A tower defense game called Fieldrunners <a href="http://wp.appadvice.com/wp-content/uploads/2010/04/IMG_0005.jpg">[6]</a>' title='Left: AdaptiveTD. Right: A tower defense game called Fieldrunners <a href="http://wp.appadvice.com/wp-content/uploads/2010/04/IMG_0005.jpg">[6]</a>'><div class='caption'>Left: AdaptiveTD. Right: A tower defense game called Fieldrunners <a href="http://wp.appadvice.com/wp-content/uploads/2010/04/IMG_0005.jpg">[6]</a></div></div>

<h2 id='adaptive_tower_defense_-_a_short_overview'>A short overview</h2>
<p>
AdaptiveTD is a real-time strategy game, more precisely it would be referred to as a tower defense game. As you can see in <a href='#tdimg' class='figref'>this figure</a>, both images have some sort of path that the enemies, like the ones below in <a href='#enemies' class='figref'>this figure</a>, can walk upon.
</p>

<div id='enemies' class='figure'><img src='Images/enemies.png' alt='Enemies from AdaptiveTD' title='Enemies from AdaptiveTD'><div class='caption'>Enemies from AdaptiveTD</div></div>

<p>
The goal of both games is to build enough towers, like the ones in <a href='#towers' class='figref'>this figure</a> below, that will try to kill the enemies, before they can cross the path. If too many enemies cross the path, the player will lose.
</p>

<div id='towers' class='figure'><img src='Images/towers.png' alt='Towers from AdaptiveTD' title='Towers from AdaptiveTD'><div class='caption'>Towers from AdaptiveTD</div></div>

<p>
In order to build towers, the player needs money/gold represented by the number next to the symbol seen in <a href='#gold' class='figref'>this figure</a> below. Whenever the player to kill an enemy, it will bring in gold to his or her money bank.
</p>

<div id='gold' class='figure'><img src='Images/gold.png' alt='Gold is represented by the number next to this symbol' title='Gold is represented by the number next to this symbol'><div class='caption'>Gold is represented by the number next to this symbol</div></div>

<p>
Already here, there are a lot of parameters that can be tweaked in order to maximize fun. For instance, one could change the balance between the build cost for each tower, and the amount of gold gaind from killed enemies. Another example is to change the health of enemies, making them more or less vulnerable to attack, while at the same time adjusting the damage that each tower does, so that the overall difficulty balance is not changed. As you can see, there are a lot of underlying parameters, and small changes can be enough to make or break a fun tower defense game. The problem with all these underlying parameters is that they can be hard to observe, thus the player does not know that the game has actually changed. That is why it is important to give the player some visual feedback that the game has changed. An example shown in <a href='#colordifference' class='figref'>this figure</a> below, shows that the background color of the game changes in direct relation to the level of enemy health, thus making a more difficult game look darker, and easier games brighter.
</p>

<div id='colordifference' class='figure'><img src='Images/darkbright.png' alt='The level of enemy health (difficulty) is reflected in the background color' title='The level of enemy health (difficulty) is reflected in the background color'><div class='caption'>The level of enemy health (difficulty) is reflected in the background color</div></div>

<p>
Also, AdaptiveTD provides the player with three different sliderbars, see <a href='#sliderbars' class='figref'>this figure</a>, game music playback speed, based on enemy speed, earthquakes that make the game screen shake, and different sizes and symbols on enemies, see <a href='#enemies' class='figref'>this figure</a> to let the player know that the game is changing.
</p>

<<<<<<< HEAD
<div id='phone' class='figure'><img src='Images/phone.jpg' alt='AdaptiveTD on a mobile device' title='AdaptiveTD on a mobile device'><div class='caption'>AdaptiveTD on a mobile device</div></div>

<h2 id='parameters'>Parameters and their importance</h2>
=======
<div id='sliderbars' class='figure'><img src='Images/sliderbars.png' alt='Sliderbars that indicate the current level of enemy health, enemy speed and tower damage' title='Sliderbars that indicate the current level of enemy health, enemy speed and tower damage'><div class='caption'>Sliderbars that indicate the current level of enemy health, enemy speed and tower damage</div></div>

<p>
In <a href='#parameters' class='chapref_2'>Parameters and Adaptivity</a> we provide a detailed list of many of the chosen parameters, how they impact the game, and why they were chosen.
</p>

<h2 id='parameters'>Parameters and Adaptivity</h2>
<p>
In AdaptiveTD we keep track of 15 different parameters, that are represented in 12 different relations. These 12 relations are important to keep the game difficulty balanced at all times, by letting related parameters be adjusted whenever a parameter is changed. In <a href='#relations' class='figref'>this figure</a> we provide the most important relations and parameters in AdaptiveTD.
</p>

<div id='relations' class='figure'><img src='Images/relations.png' alt='Parameters in relation to each other' title='Parameters in relation to each other'><div class='caption'>Parameters in relation to each other</div></div>

<p>
Every relation involving at least to parameters has a number next to each parameter. This number represents the proportion of how much a parameter should change, when another one is changed. For instance in relation 1, Tower Build Cost Multiplier and Enemy Gold Yield Multiplier both have the number '1' next to them. This means, that if one of them is changed by a certain value, the other one should also change with the same value, thus they are still in balance. Relation 2 is inverse proportional, but similar to relation 1, in that if one of them changes with a value, the other one should change with the same, negative value. Relation 3 is different, because it involves three parameters, but it functions in the same way. If Enemy Health Multiplier is changed, then Enemy Speed Multiplier should change by half the negative value, and Tower Damage whould change by half the value. Note that Enemy Speed Multiplier and Enemy Health Multiplier is in the same relation twice. This is not a problem, because if one relation deides to change the internal balance, the other relations are not influenced. So if Enemy Speed Multiplier changes in one relation, the change will NOT propagate to the other relations.
</p>

<p>
These relations and numbers are what we believe is approximately good enough to keep the difficulty balance constant. For instance, if the Enemy Health increases by 50%, it should be sufficient that Tower Damage is also increased by 50%, in order to keep balance. Of course, towers that do not deal direct damage, but have a more tactical effect, such as slowing the current speed of an enemy, will be somewhat less efficient after a balancing change like this. This makes the difficulty scaling in the game less predictable.
</p>

<p>
To the left there are four parameters that are not in relation with any other parameters. They are still in relation with themselves, in order to be able to jump, more about jumping in the <a href='#algorithm' class='chapref_2'>Algorithm</a> chapter. These four parameters hold the probabilities digger and super enemies to appear and the probability for earthquakes to occur, all of which are described more in detail below.
</p>

<p>
Probability for a super enemy to appear is a value from 0 to 1 that the next enemy generated will have some super properties, i.e. have more health, more speed, sometimes be invisible and be impossible to harm for a short time period, as seen in <a href='#super' class='figref'>this figure</a>.
</p>

<div id='super' class='figure'><img src='Images/super.png' alt='A tough enemy who has been given extra, super abilities an enemy can have at a time: More health, more speed, invisibility and impossible to harm' title='A tough enemy who has been given extra, super abilities an enemy can have at a time: More health, more speed, invisibility and impossible to harm'><div class='caption'>A tough enemy who has been given extra, super abilities an enemy can have at a time: More health, more speed, invisibility and impossible to harm</div></div>

<p>
Probability for a digger enemy to appear works a little differently from super abilities. A game consists of 45 enemies, with four possible types of enemies that can be generated. The "Probability for a digger enemy to appear" parameter is simply the probability that each of these 45 enemies is a digger. So a value of 0.67 out of 1, should result in approximately 30 diggers, which is really a challenge. In the <a href='#discussion' class='chapref_1'>Discussion</a> chapter we discuss some weaknesses of this approach. Below is a figure of a digger enemy and what it can do.
</p>

<div id='digger' class='figure'><img src='Images/digger.png' alt='The digger enemy is a difficult opponent' title='The digger enemy is a difficult opponent'><div class='caption'>The digger enemy is a difficult opponent</div></div>

<p>
The earthquake functionality shakes the game screen, causing towers to be randomly moved, unless they have been properly built or upgraded. The earthquake is dependant upon two parameters, the first which is the Probability for earthquakes to be turned on at all, and the probability that earthquakes occur, if they are on at all. In <a href='#discussion' class='chapref_1'>Discussion</a> we discuss the earthquake functionality, as we received some mixed feedback on it.
</p>
>>>>>>> Report work before submit

<p>
The rest of the parameters are more subtle, only changing underlying variables. In the <a href='#algorithm' class='chapref_2'>Algorithm</a> chapter we go through in detail how the game jumps to change its content and difficulty.
</p>

<h2 id='adaptive_tower_defense_-_adaptivetd_vs__similar_games'>AdaptiveTD vs. similar games</h2>
<p>
AdaptiveTD is very similar to classic tower defense games, in that the player has to stop different kinds of enemies from reaching the destination on their path, by using different kinds of towers. AdaptiveTD differs slightly from other tower defense games on several points.
</p>

<p>
There are no scripted or static levels, since each game is a step closer towards the player's 'ideal game', that is, the game that is perceived as the most fun. Other than that the game learns after each level, the player has nothing that is carried over to the next game, such as tower access, special items or game progress in general. The player simply plays successive games until he or she quits.
</p>

<p>
The game has modular towers and enemies. This is not necessarily new to the tower defense genre, as not all tower defense games may have pre-defined enemies and towers, but this is something that can be used in order to adapt the game towards personal preferences. (Guided) Randomly generated maps. Not necessarily new to the genre either, but is another useful technology that can be used to adapt the game to the player. Note that our game did not use this for game adaption, only to make the game seem less static.
</p>

<h2 id='adaptive_tower_defense_-_tools_and_publishing'>Tools and publishing</h2>
<p>
We created AdaptiveTD using LibGDX, which is "a cross-platform game development library written in Java", that "abstracts away the differences between writting desktop, Android, iOS and HTML5 games based on standards like OpenGL ES/WebGL", where "Applications can be prototyped and developed entirely on the desktop, then only 6 lines of code are needed to run your app on Android or HTML5." <a href="https://code.google.com/p/libgdx/">[7]</a>.<br>
This makes it possible to test and possibly publish AdaptiveTD on Android and iPhones, as well as tablets and computers, both for desktop in all major OS's, and for HTML.
</p>

<div id='phone' class='figure'><img src='Images/phone2.jpg' alt='AdaptiveTD on a mobile device' title='AdaptiveTD on a mobile device'><div class='caption'>AdaptiveTD on a mobile device</div></div>

<p>
Since this is only a proof of concept game meant for testing purposes, we are not planning on publishing the game, nor make it publicly available. However, in <a href='#futurework' class='chapref_1'>Future Work</a> we present some possibilities for further development and use for AdaptiveTD.
</p>

<h1 id='shc'>Stochastic hill climbing</h1>

<p>
A hill climbing algorithm is an iterative improvement algorithm, searching for a local maximum. It tries to maximize a function f(X), where X could be a node, state, position or, in our case, a vector of parameters. It compares neighboring nodes to the one it is standing on, and checks if they are an improvement on f(X). If one of the other nodes is improving the situation, then the algorithm moves to the new node, commonly the best node, and repeats the process. The process is repeated until no more improvements can be found, thus the algorithm has found a local maximum. <a href='#reference_8' title='Russell, S. J., & Norvig, P. (1995), <i>Artificial Intelligence: A Modern Approach</i>. Upper Saddle River, NJ: Prentice Hall'>[8]</a>. 
</p>

@figure(pseudoshc, pseudoStochastic.png, Pseudo-code for Stochastic Hillclimbing, as done in <a href='#shce' class='chapref_2'>Stochastic hill climbing example</a>.)

<div id='hclocalmaximum' class='figure'><img src='Hill_Climbing_Local_Maximum.png' alt='A function that has a local maximum' title='A function that has a local maximum'><div class='caption'>A function that has a local maximum</div></div>
<div id='hcflat' class='figure'><img src='Hill_Climbing_Flat.png' alt='A function that is too flat to search on' title='A function that is too flat to search on'><div class='caption'>A function that is too flat to search on</div></div>
<div id='hcsteep' class='figure'><img src='Hill_Climbing_Steep.png' alt='A function that is very steep' title='A function that is very steep'><div class='caption'>A function that is very steep</div></div>

<p>
One issue with this algorithm, is that it can become stuck on a local maximum, which may not be the global maximum, as in <a href='#hclocalmaximum' class='figref'>this figure</a>. One way to reduce the probability of this to happen, is to allow the algorithm to jump larger distances each jump, or to make sure that the landscape is convex. Another issue shown by <a href='#hcflat' class='figref'>this figure</a> is that the search area may be flat, that is, each node is as good as all its neighbors. In this case, any jump will not bring any improvement. A third issue in <a href='#hcsteep' class='figref'>this figure</a> is that a node may be lying on a very steep ridge, that is, the 'area' of parameters that give a good node is very small, and can thus be hard to find. <a href='#reference_8' title='Russell, S. J., & Norvig, P. (1995), <i>Artificial Intelligence: A Modern Approach</i>. Upper Saddle River, NJ: Prentice Hall'>[8]</a>
</p>

<p>
There are different variants of hill climbing algorithms, with different ways of deciding where and when to jump. The stochastic hill climbing algorithm, closely resembling simulated annealing, chooses a position at random, then evaluates whether it is an improvement, and if it is, jumps to the new position. If the new position is not an improvement, it will go back to the last one. With stochastic hill climbing, it may be wise to set a specific maximum jump distance, and let this decrease over time. This allows the algorithm to converge or settle on a position after some time. <a href='#reference_8' title='Russell, S. J., & Norvig, P. (1995), <i>Artificial Intelligence: A Modern Approach</i>. Upper Saddle River, NJ: Prentice Hall'>[8]</a>
</p>

<h2 id='shce'>Stochastic hill climbing example</h2>

<p>
Here is an example for how to use stochastic hill climbing for how to find the maximum value of the function f(X) = 2 - X<sup>2</sup>. which has a maximum value of 2. We initialize the maximum jump distance (in x-direction) to a value of 1.0, and let this decrease by 0.1 with each jump.
</p>

<div id='hcex1' class='figure'><img src='Hill_Climbing_Example_1.png' alt='The startpoint for the search' title='The startpoint for the search'><div class='caption'>The startpoint for the search</div></div>
<div id='hcex2' class='figure'><img src='Hill_Climbing_Example_2.png' alt='The first jump' title='The first jump'><div class='caption'>The first jump</div></div>
<div id='hcex3' class='figure'><img src='Hill_Climbing_Example_3.png' alt='An attempted jump' title='An attempted jump'><div class='caption'>An attempted jump</div></div>
<div id='hcex4' class='figure'><img src='Hill_Climbing_Example_4.png' alt='Achieving global maximum' title='Achieving global maximum'><div class='caption'>Achieving global maximum</div></div>
<div id='hcex5' class='figure'><img src='Hill_Climbing_Example_5.png' alt='Further jumps are discarded' title='Further jumps are discarded'><div class='caption'>Further jumps are discarded</div></div>

<p>
This is a short example of how stochastic hill climbing will eventually find the local, or global, maximum on a graph. This example is very short, compared to how many jumps it would normally take, but this is actually possible.
</p>

<p>
With a starting maximum jump distance of 1.0, decreasing by 0.1 with each jump, the algorithm will have converged after ten jumps, hopefully at an acceptable position. In a game setting, it may be wise to let the maximum jump distance never decrease to zero, because it can make the game feel more lively.
</p>

<h1 id='solution'>Solution</h1>

<p>
In this chapter we will talk about our solution which is an implementation of the Stochastic Hillclimbig algorithm along with a few features needed to adapt it for our use. We work with the paramteres listed in <a href='#app_1' class='chapref_1'>Appendix I - Parameters</a>.
<<<<<<< HEAD
</p>

<h2 id='solution_-_algorithm'>Algorithm</h2>

<div id='pseudoalgorithm' class='figure'><img src='pseudoAlgorithm.png' alt='Pseudo-code for the algorithm.' title='Pseudo-code for the algorithm.'><div class='caption'>Pseudo-code for the algorithm.</div></div>


<div id='algorithmexample' class='figure'><img src='algorithm.png' alt='The flow of our algorithm.' title='The flow of our algorithm.'><div class='caption'>The flow of our algorithm.</div></div>

<p>
As indicated in <a href='#pseudoalgorithm' class='figref'>this figure</a> and <a href='#algorithmexample' class='figref'>this figure</a> we start with set values for all parameters, which is a prior we have found to give a decent game. After playing a game the user gives feedback we use to create the metric is "How fun was this game?" and "How difficult was this game?". The first one presents the user with three hearts, and for each heart selected we roll a die from one to ten one time. This number is multiplied with a multiplier which increases as more games are played. This is to not end up stuck in a place just because the feedback received a high random value.
</p>

<h2 id='solution_-_litt_lang_setning__som_er_en_hel_paragraf_'>Litt lang setning, som er en hel paragraf?</h2>
<p>
After the metric has been created we compare it with the currently best known metric, and if we find that the new metric is better we save these as the best known metric conintue to jump from there, else we restore the parameters from the game where we received the best metric.
</p>

<div id='pseudorelations' class='figure'><img src='pseudoRelations.png' alt='Pseudo-code for jumping of relations' title='Pseudo-code for jumping of relations'><div class='caption'>Pseudo-code for jumping of relations</div></div>

<p>
We randomly increase or decrease the parameters with parameters from zero up to a max jump distance, and let the user play again and repeat the process. The max jump distance decreases each time we find a better game, and thus we attempt to converge at a point where the user enjoys the game. Perceived fun is fleeting though, and if the user grows tired of an area he might start to rate it lower, and thus when a user gives a game the lowest rating we increase the max jump distance, to enable users to find new games.
=======
>>>>>>> Report work before submit
</p>

<h2 id='algorithm'>Algorithm</h2>

<div id='pseudoalgorithm' class='figure'><img src='pseudoAlgorithm.png' alt='Pseudo-code for the algorithm.' title='Pseudo-code for the algorithm.'><div class='caption'>Pseudo-code for the algorithm.</div></div>


<div id='algorithmexample' class='figure'><img src='algorithm.png' alt='The flow of our algorithm.' title='The flow of our algorithm.'><div class='caption'>The flow of our algorithm.</div></div>

<p>
As indicated in <a href='#pseudoalgorithm' class='figref'>this figure</a> and <a href='#algorithmexample' class='figref'>this figure</a> we start with set values for all parameters, which is a prior we have found to give a decent game. After playing a game the user gives feedback we use to create the metric is "How fun was this game?" and "How difficult was this game?". The first one presents the user with three hearts, and for each heart selected we roll a die from one to ten one time. This number is multiplied with a multiplier which increases as more games are played. This is to not end up stuck in a place just because the feedback received a high random value.
</p>

<h2 id='solution_-_litt_lang_setning__som_er_en_hel_paragraf_'>Litt lang setning, som er en hel paragraf?</h2>
<p>
After the metric has been created we compare it with the currently best known metric, and if we find that the new metric is better we save these as the best known metric conintue to jump from there, else we restore the parameters from the game where we received the best metric.
</p>

<div id='pseudorelations' class='figure'><img src='pseudoRelations.png' alt='Pseudo-code for jumping of relations' title='Pseudo-code for jumping of relations'><div class='caption'>Pseudo-code for jumping of relations</div></div>

<p>
We randomly increase or decrease the parameters with parameters from zero up to a max jump distance, and let the user play again and repeat the process. The max jump distance decreases each time we find a better game, and thus we attempt to converge at a point where the user enjoys the game. Perceived fun is fleeting though, and if the user grows tired of an area he might start to rate it lower, and thus when a user gives a game the lowest rating we increase the max jump distance, to enable users to find new games.
</p>

<p>
The main feature we have implemented to adapt the stochastic hillclimbing algorithm to work with our parameters is relations. We needed to change the game, while not necessarily changing the difficulty. To do this we decided to put most of the parameters in relations. We do not change all parameters individually when jumping, but cycle through all relations and jump parameter one, and parameter two is changed as defined by the relation.
</p>

<div id='relationsexample' class='figure'><img src='relationsFun.png' alt='Basic relations example.' title='Basic relations example.'><div class='caption'>Basic relations example.</div></div>

<p>
The figure above illustrate how relations work. We have the relation GlobelMonsterHP->GlobalMonsterSpeed, when one goes up, the other one goes down proportionally. This may also be between two parameters which will change in the same direction as also seen in <a href='#relationsexample' class='figref'>this figure</a> where GlobalMonsterHp->TEDamage(Tower Damage) and both increase. As you may have noted, parameters can also be in more than one relation, thus when GlobalMonsterHP changes, it affects both GlobalMonsterSpeed and TEDamage.
</p>

<div id='difficultyexample' class='figure'><img src='difficulty.png' alt='Difficulty does not change in relations.' title='Difficulty does not change in relations.'><div class='caption'>Difficulty does not change in relations.</div></div>

<p>
<<<<<<< HEAD
The main feature we have implemented to adapt the stochastic hillclimbing algorithm to work with our parameters is relations. We needed to change the game, while not necessarily changing the difficulty. To do this we decided to put most of the parameters in relations. We do not change all parameters individually when jumping, but cycle through all relations and jump parameter one, and parameter two is changed as defined by the relation.
</p>

<div id='relationsexample' class='figure'><img src='relationsFun.png' alt='Basic relations example.' title='Basic relations example.'><div class='caption'>Basic relations example.</div></div>

<p>
The figure above illustrate how relations work. We have the relation GlobelMonsterHP->GlobalMonsterSpeed, when one goes up, the other one goes down proportionally. This may also be between two parameters which will change in the same direction as also seen in <a href='#relationsexample' class='figref'>this figure</a> where GlobalMonsterHp->TEDamage(Tower Damage) and both increase. As you may have noted, parameters can also be in more than one relation, thus when GlobalMonsterHP changes, it affects both GlobalMonsterSpeed and TEDamage.
</p>

<div id='difficultyexample' class='figure'><img src='difficulty.png' alt='Difficulty does not change in relations.' title='Difficulty does not change in relations.'><div class='caption'>Difficulty does not change in relations.</div></div>

<p>
=======
>>>>>>> Report work before submit
We also get feedback on the difficulty, while this is not the main focus of this report, it does indicate something about the user. Since a game that is to easy or to hard is not fun, we found that we needed to implement some sort of difficulty scalign as well. We have implemented Stochastic Hillclimbing for the difficulty. Here however we just have parameters, and since the metric here in the sense of a graph would be "Too Low"(Easy), "Perfect" and "Too High"(Difficult), it is quite easy to guide the search and make it less random.
</p>

<h1 id='testing'>Testing</h1>
<p>
Our testing is split into two parts. The first part contains two case tests of the algorithm, and the second part contains tests from our fellow students and friends.
</p>

<h2 id='testing_-_difficulty_testing'>Difficulty testing</h2>
<p>
This is how our algorithm performed.
</p>

<h2 id='fun_testing'>Fun testing</h2>
<p>
After we finished the game, we ran several tests to research the viability of our algorithm.
</p>

<h3 id='rpt'>Real Playtests</h3>
<p>
We ran some actual playtests, having people who had never played the game before download and play it. These people varied in age, computer background, and experience with games, to get a sense whether we could please a wide variety of people by adapting to their preferences.
</p>

<p>
While it is hard to plot exactly what they thought, since measuring fun is not an exact science we have gathered some feedback from them which we will summarize here.
</p>

<p>
- The game is fun to begin with, but gets somewhat monotone when you play it for an extended period of time. <br>
- It is exciting when the game changes radically and new stuff happens that you have to deal with.<br>
- The difficulty scales well, and you can feel the changes quickly if you are dissatisfied with your game.<br>
- 
</p>

<p>
There are also some stats that certain people enjoy whiel others do not enjoy, and since the jumping is currently random for 15 parameters you may end up with not getting everything you desire. The main thing we heard here was that the diggers, as talked about in <a href='#parameters' class='chapref_2'>Parameters and their importance</a> can quickly become overwhelming if you get an unlucky jump while the max jump distance is still high. While you should generally end up with your old parameters if you did not enjoy the game, there are cases where the one roll of the die from one heart can give a metric higher than the old best metric. We have discussed never picking the current parameters the best known if a user rated it with one heart, however we have not had the time to do playtests using this, but believe it would give a better experience.
</p>

<h3 id='testing_-_fun_testing_-_case_tests'>Case tests</h3>
<p>
We also did some case tests ourselves, where we decided on a parameter which we wanted to maximize or minimize, and tested if we would get the desired result. We created some methods to make these tests quick, and played. For each test we played 15 games, and gave the game three hearts if it went in the correct direction with our stat, and one if not. We also gave the game the feedback of "Perfect" in the difficulty, such that this part of the game did not alter any stats.
</p>

<b>Case Test one: Global Reload Time maximized</b>

<p>
For this test we attempted to maximize the Global Reload time. Which means that the parameter GlobalReloadTime should preferably go upwards as we play.
</p>

<p>
Here are the plot from five playthroughs attempting this.
</p>

<div id='reloadfun' class='figure'><img src='GlobalReloadfuntest.png' alt='Plot of the case tests for Global Reload time.' title='Plot of the case tests for Global Reload time.'><div class='caption'>Plot of the case tests for Global Reload time.</div></div>

<div id='avgreloadfun' class='figure'><img src='avgGlobalReloadfuntest.png' alt='Average values from the case tests for Global Reload time.' title='Average values from the case tests for Global Reload time.'><div class='caption'>Average values from the case tests for Global Reload time.</div></div>

<p>
As you can see it is moderately successfull each time, but since the jumps are random we do expect jagged graphs as it is as likely to decrease as it is to increase. The trend is however quite clear, the GlobalReloadTime is increasing. We believed that this could also be made even more clear by never choosing the parameters after choosing one heart, as described in the end of <a href='#rpt' class='chapref_3'>Real Playtests</a> after it was pointed out by one of the subjects in the playtest, and we tested with exactly this, as plotted below.
</p>

<div id='postreloadfun' class='figure'><img src='PostHighReloadFuntest.png' alt='Plot of the case tests after one heart not chosen.' title='Plot of the case tests after one heart not chosen.'><div class='caption'>Plot of the case tests after one heart not chosen.</div></div>

<p>
This had little effect, but we do believe that it will help users not get stuck in with a game they disliked as the currently best known game. It performed a little better than the old one on the 15th game, but a 5 * 15 games is not enough to be conclusive. We wish we had the time to automate tests and run the test more times with more games to see whether it is acctually better, worse or equal. Following is the plot of the average from both tests, blue is the average from the tests where one heart could still be chosen as best known, green is the average from the tests where it could not.
</p>

<div id='avgreloadpostreload' class='figure'><img src='avgbothreloads.png' alt='Average Reload time for all playthroughs for both versions.' title='Average Reload time for all playthroughs for both versions.'><div class='caption'>Average Reload time for all playthroughs for both versions.</div></div>

<p>
We also used these tests to see that the relations work correctly. GlobalReloadTime affect TEDamage, such that if the reload time goes up, the damage should also increase. Here is a plot of one of the more successfull playthroughs, with GlobalReloadTime in blue and TEDamage in green. Damage is also affected by other relations, which is why there are deviations in the values.
</p>

<div id='reloaddamage' class='figure'><img src='figreloadrelateddamage.png' alt='Plot of how global reload and tower damage changed over time.' title='Plot of how global reload and tower damage changed over time.'><div class='caption'>Plot of how global reload and tower damage changed over time.</div></div>

<p>
As you can see they increase almost simultaneously.
</p>

<h1 id='discussion'>Discussion</h1>

<p>
In this chapter, we discuss three topics. First we discuss the results from the fun testing, then the results from the difficulty or case testing, and lastly we discuss some other observations noted during the development process.
</p>

<h2 id='discfun'>Discussing the fun testing</h2>
<p>
When looking at the fun testing results, we see that our game was generally rated fun, with an average of 7.17 our of 10. But since our testers were mainly friends and fellow students, we were expecting to receive rather high values, as they did not want to make us feel bad. But a 7.17 out of 10 is not actually bad for the game itself, as much of the game content, such as audio and graphics, was made without a budget. But a difficult aspect of this project, is that it is hard to measure whether something is fun or not. Our main feedback for how well the game worked is the ratings from players, and from that we are satisfied with how fun the game was perceived to be, but even if the game was characterized 10 out of 10, the test results could mostly reflect the game and its contents, and not tell us much about the algorithm itself.
</p>

<p>
The second part of the fun testing results tells us more about the algorithm itself. The results reveal that the subjects thought the game was actually becoming worse over time, instead of maximizing fun. As mentioned in <a href='#fun_testing' class='chapref_2'>Fun testing</a>, we believe that two of our parameters, named "SuperChance" and "DiggerChance", see <a href='#app_2' class='chapref_1'>Appendix II - Example Logfile</a>, should have been normalized. As of now, they have too big an impact on the game, because their values are varying too much each jump. To the best of our knowledge, this is a result of our modified algorithm, which we believe can be fixed by having multiple specialized algorithms, instead of a central one. Another solution could be to only alter a single parameter each jump, because the algorithm would then be more sure about what the player enjoyed after each jump. This latter solution would make the algorithm work more slowly, which is maybe a too valuable trade-off.
</p>

<h2 id='discussion_-_discussing_the_difficulty_testing'>Discussing the difficulty testing</h2>
<p>
The difficulty test results are good, in that the algorithm is able to change the difficulty based on the feedback it receives, relatively quickly. However, the algorithm we use for difficulty scaling is not the same as the one we use for maximizing fun. Since the difficulty can only be either too difficult, perfect or too easy, it is easier to scale difficulty, than to maximize fun.
</p>

<h2 id='observations'>Other observations</h2>
<p>
Another problem we have noticed during the development process, is that the jumps themselves may be too subtle for a player to notice when jump distance shortens. The algorithm requires positive feedback when it goes in a direction the player likes, but if the change is not noticable the player may give it the same score, thus have a decent chance of ending up jumping from his old game each jump. This issue is similar to the one in chapter 5, <a href='#shc' class='chapref_1'>Stochastic hill climbing</a>, <a href='#hcflat' class='figref'>this figure</a>.
</p>

<p>
Lastly, we also noticed that the tower defense genre may not be well suited for creating an adaptive game. This is mainly because of the three following reasons. Firstly, the core game elements are rather static, which makes it difficult to make the game look and feel adaptive to the player. A different genre, such as the platformer, with game a example like Super Mario Bros. <a href="http://mario.nintendo.com/">[9]</a>. Secondly, the parameters in a tower defense game are very tightly knit together, in order to keep the game difficulty in balance. It is difficult to map how they all fit together, which makes it difficult for our algorithm to jump randomly to a new position, while still maintaining mentioned balance. Thirdly, the fun factor in a tower defense game is often related to the feeling of accomplishment. For instance, this feeling may occur when the player has lost a couple of games at the same challenge, and finally is able to beat the game. Since the game adapts itself to the player, thus is never the same, some would feel that their accomplishment is diminished.
<<<<<<< HEAD
=======
</p>

<p>
A problem with the relations, is that a parameter which is represented in many relations will have a higher probability to increase or decrease more drastically, as each relation gives every parameter it holds a chance to jump. Also, our predefined relations are not completely preserving the game difficulty at each jump, making the fun search of our algorithm also slightly change the game difficulty at the same time.
</p>

<p>
The diggers, super enemies and earthquake functionality is probably what makes AdaptiveTD 
>>>>>>> Report work before submit
</p>

<h1 id='conclusion'>Conclusion</h1>
<p>
Although some of the test results came out negative, we still believe that the concept of adapting a game to an individual is something that can be done, in order to maximize fun. The game itself was considered fun, and we believe that some of the reason lays in the variety of the game, caused by its adaptivity. But in order to be able to maximize fun, the algorithm needs to become more refined, and could work much better if we fetch specialized information, indicating what the player really enjoyed. This information could then be used to let the algorithm do a more guided search to find out where to jump next, and not do a completely random jump. On the other hand, the difficulty scaling, works very well, and is something that we can re-use in later projects, such as for E-learning purposes.
</p>

<p>
As noted in <a href='#observations' class='chapref_2'>Other observations</a>, the 'flat-issue' that can be experienced with hill-climbing in general, also occurred at some point during our own development process. In order to combat this, an adaptive game itself needs to have much and varied game content, so the different games is felt different by the player. The player can then give better feedback to how the game was, and whether the algorithm should jump from a new location or not.
</p>

<p>
We would also probably have gotten a better result by choosing a different game genre than tower defense. When the game uses a stochastic hill climbing algorithm relying on too many parameters, it is unlikely that all will go in an optimal direction at once. As mentioned in the second part of <a href='#discfun' class='chapref_2'>Discussing the fun testing</a>, we believe that if the game had used multiple specialized algorithms, which examines fewer parameters at a time, the total algorithm could have been more precise in its jumps. If specialized enough, one of the algorithms could also automatically detect feedback through how a player plays, rather than requiring a questionnaire at the end.
</p>

<p>
If we do stochastic hill climbing based on metrics created based on how the player is playing, on few parameters for each part of the algorithm, we believe that we could get much better results. However, as this has been, to the best of our knowledge, the first venture into creating games which adapt based on fun, we are quite happy with our result.
</p>

<p>
SPØRRE ROBIN
</p>

<h1 id='futurework'>Future Work</h1>

<p>
The algorithm works ok, but it needs to be more refined. We believe that with some work refining the algorithm, and doing more testing with different sensors to see if certain feedback can be interprented to liking certain things in the game, we can create a great algorithm to maximize fun even in games with many parameters.
</p>

<p>
We would like to try to implement this sort of algorithm in a game related to e-learning. Currently one of the problems with e-learning games is that they feel to much like learning and to little like games. If we could be able to create a game which can maximize the fun a player has, while also scaling the difficulty appropriately we believe we could create an effective learning tools for many skills.
</p>

<p>
With a more refined algorithm we believe this could be highly useful in a game, however it needs more sensors or ways to detect which parameters the players are satisfied with and not. There are also interesting applications for this sort of algorithm in E-learning, if we can detect how to make an e-learning game fun for a player and also scale the difficulty to their ability we may create an effective game for learning.
</p>

<p>
Use search algorithm also for relations. We have most of the implementation ready for this, but the theory behind is a little more complex than the scope of this project.
</p>


<h1 id='references'>References</h1>

<p>
IEEE, ACM, Springer
</p>

<div>
<span id='reference_1'>[1] Tavangarian, D., Leypold, M. E., Nölting, K., Röser, M., & Voigt, D. (2004). Is e-learning the Solution for Individual Learning. <i>Electronic Journal of E-learning</i>, 2(2), 273-280.</span><br>
<span id='reference_2'>[2] Marczewski, A. (2012). <i>Gamification: A Simple Introduction.</i> Andrzej Marczewski.</span><br>
<span id='reference_3'>[3] Zichermann, G., & Cunningham, C. (2011). <i>Gamification by design: Implementing game mechanics in web and mobile apps.</i> O'Reilly Media.</span><br>
<span id='reference_4'>[4] Huotari, K., & Hamari, J. (2012, October). Defining gamification: a service marketing perspective. In <i>Proceeding of the 16th International Academic MindTrek Conference</i> (pp. 17-22). ACM.</span><br>
<span id='reference_5'>[5] Spronck, P., Sprinkhuizen-Kuyper, I., & Postma, E. (2004). Difficulty scaling of game AI. In <i>Proceedings of the 5th International Conference on Intelligent Games and Simulation (GAME-ON 2004)</i> (pp. 33-37).</span><br>
<a id='reference_6' href="http://wp.appadvice.com/wp-content/uploads/2010/04/IMG_0005.jpg">[6] http://wp.appadvice.com/wp-content/uploads/2010/04/IMG_0005.jpg</a><br>
<a id='reference_7' href="https://code.google.com/p/libgdx/">[7] https://code.google.com/p/libgdx/</a><br>
<span id='reference_8'>[8] Russell, S. J., & Norvig, P. (1995), <i>Artificial Intelligence: A Modern Approach</i>. Upper Saddle River, NJ: Prentice Hall</span><br>
<a id='reference_9' href="http://mario.nintendo.com/">[9] http://mario.nintendo.com/</a><br>
</div>


<h1 id='app_1' class='notoc'>Appendix I - Parameters</h1>

<p>
Following is a list of the parameters the game changes, and their function.
</p>

<ul>
<li>GlobalMonsterHP - Affects the HP of all enemies.</li>
<li>TEDotDamage - Affects the damage of each tick for the damage over time tower.</li>
<li>TEDotTicks - Affects how many ticks of damage the damage of time tower does.</li>
<li>TESlowPercentage - Affects the amount of slow the frost tower causes to an enemy.</li>
<li>TESlowDuration - Affects the duration of the slow from the frost tower.</li>
<li>GlobalReloadTime - Affects reload time for all towers.</li>
<li>TEDamage - Affects damage for all towers.</li>
<li>GlobalBuildCost - Affects cost to build each tower.</li>
<li>GlobalMonsterSpeed - Affects the speed of all enemies.</li>
<li>GlobalMonsterGoldYield - Affects how much gold each enemy yields.</li>
<li>GlobalTowerRange - Affects how far towers can shoot.</li>
<li>DiggerChance - Affects how often an enemy will be a digger.</li>
<li>SuperChance - Affects how often an enemy will have one or more super effects.</li>
<li>EarthquakeChance - Affects how often earthquakes are enabled and disabled.</li>
<li>EarthquakeChanceInGame - Affects how often there is an earthquake when enabled.</li>
</ul>

<h1 id='app_2' class='notoc'>Appendix II - Example Logfile</h1>

<p>
This is an example log file as generated when someone plays the game.
</p>

<p>
Game number 1 - at May 23, 2013 12:33:20 PM - Game WON<br>
Lives left        : 10/10<br>
Gold left         : 90/100<br>
Earthquake count  : 9<br>
Shots fired       : 607
</p>
<p style='text-align: center'>-Tower information---</p>
<p>
Towers built      : 12<br>
Upgrades bought   : 0<br>
Towers sold       : 0<br>
Towers destroyed  : 0<br>
Earthquake proofs : 0<br>
Arrow towers      : 1<br>
Frost towers      : 2<br>
Cannon towers     : 2<br>
Flame towers      : 0<br>
Laser towers      : 4<br>
Burning towers    : 3
</p>
<p style='text-align: center'>-Metric and jump information---</p>
<p>
Hearts feedback        : 0<br>
Difficulty feedback    : 0<br>
Last metric            : 0.0<br>
Challenger metric      : 0.0<br>
Max jump distance      : 0.4<br>
Player Level           : 0.0<br>
Game length multiplier : 1.0
</p>
<p style='text-align: center'>-Enemy information---</p>
<p>
Total enemies killed : 45/45<br>
Basic enemies killed : 14/15<br>
Fast enemies killed  : 14/15<br>
Tough enemies killed : 17/18<br>
Diggers killed       : 0/0<br>
Total supers killed  : 0/0<br>
Super fast   killed  : 0/0<br>
Super tough  killed  : 0/0<br>
Super shield killed  : 0/0<br>
Super invis  killed  : 0/0
</p>
<p style='text-align: center'>-Parameters---</p>
<p>
TEDotDamage:             1.0         Min: 0.1   Max: 3.0<br>
TEDamage:                1.0         Min: 0.01  Max: 10.0<br>
DiggerChance:            0.2         Min: 0.0   Max: 1.0<br>
EarthquakeChance:        0.2         Min: 0.0   Max: 1.0<br>
GlobalMonsterHP:         1.0         Min: 0.1   Max: 3.0<br>
SuperChance:             0.2         Min: 0.0   Max: 1.0<br>
TESlowDuration:          1.0         Min: 0.1   Max: 3.0<br>
EarthquakeChanceInGame:  0.2         Min: 0.1   Max: 0.9<br>
GlobalReloadTime:        1.0         Min: 0.1   Max: 3.0<br>
GlobalTowerRange:        1.0         Min: 0.1   Max: 10.0<br>
GlobalMonsterGoldYield:  1.0         Min: 0.1   Max: 3.0<br>
GlobalMonsterSpeed:      1.0         Min: 0.1   Max: 10.0<br>
TESlowPercentage:        1.0         Min: 0.1   Max: 1.4<br>
GlobalBuildCost:         1.0         Min: 0.1   Max: 3.0<br>
TEDotTicks:              1.0         Min: 0.1   Max: 3.0
</p>

<p>
Game number 2 - at May 23, 2013 12:34:49 PM - Game LOST<br>
Lives left        : 0/10<br>
Gold left         : 21/110<br>
Earthquake count  : 0<br>
Shots fired       : 324
</p>
<p style='text-align: center'>-Tower information---</p>
<p>
Towers built      : 11<br>
Upgrades bought   : 0<br>
Towers sold       : 0<br>
Towers destroyed  : 3<br>
Earthquake proofs : 0<br>
Arrow towers      : 2<br>
Frost towers      : 1<br>
Cannon towers     : 2<br>
Flame towers      : 1<br>
Laser towers      : 3<br>
Burning towers    : 2
</p>
<p style='text-align: center'>-Metric and jump information---</p>
<p>
Hearts feedback        : 0<br>
Difficulty feedback    : 0<br>
Last metric            : 0.0<br>
Challenger metric      : 5.0<br>
Max jump distance      : 0.25599998<br>
Player Level           : 1.0<br>
Game length multiplier : 1.2
</p>
<p style='text-align: center'>-Enemy information---</p>
<p>
Total enemies killed : 22/45<br>
Basic enemies killed : 8/12<br>
Fast enemies killed  : 9/21<br>
Tough enemies killed : 5/11<br>
Diggers killed       : 0/3<br>
Total supers killed  : 0/3<br>
Super fast   killed  : 0/2<br>
Super tough  killed  : 0/3<br>
Super shield killed  : 0/1<br>
Super invis  killed  : 0/1
</p>
<p style='text-align: center'>-Parameters---</p>
<p>
TEDotDamage:             1.0799435   Min: 0.1   Max: 3.0<br>
TEDamage:                0.95508564  Min: 0.01  Max: 10.0<br>
DiggerChance:            0.4         Min: 0.0   Max: 1.0<br>
EarthquakeChance:        0.3330284   Min: 0.0   Max: 1.0<br>
GlobalMonsterHP:         1.1467683   Min: 0.1   Max: 3.0<br>
SuperChance:             0.4         Min: 0.0   Max: 1.0<br>
TESlowDuration:          1.2593029   Min: 0.1   Max: 3.0<br>
EarthquakeChanceInGame:  0.3         Min: 0.1   Max: 0.9<br>
GlobalReloadTime:        1.1283836   Min: 0.1   Max: 3.0<br>
GlobalTowerRange:        1.1272081   Min: 0.1   Max: 10.0<br>
GlobalMonsterGoldYield:  1.1011007   Min: 0.1   Max: 3.0<br>
GlobalMonsterSpeed:      0.8071418   Min: 0.1   Max: 10.0<br>
TESlowPercentage:        0.74069715  Min: 0.1   Max: 1.4<br>
GlobalBuildCost:         1.1011007   Min: 0.1   Max: 3.0<br>
TEDotTicks:              0.92005646  Min: 0.1   Max: 3.0
</p>
</body></html>